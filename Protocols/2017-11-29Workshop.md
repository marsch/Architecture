# Protocol

Within the workshop a general Open Integration Hub structure was developed. (See figure below).

[Openintegrationhubscenario](https://github.com/openintegrationhub/Architecture/blob/master/Assets/IntegrationProcess.svg)

The Open Integration Hub is seperated into several parts, some of which are mandatory and others are optional.
Depending on the specific Use Case Scenarios, different combiniations of the parts are needed to cover all needed functionalities.

## Findings

1. A connector consists of an adapter and a transformer and a storage (at least of one reusable adapter)
2. The adapter technically standardizes the requested data
3. The transformer normalizes the technically standardized data into a standard data Schema
4. Data storage (Data Lake) is an **optional** feature
  1. Differentiation between the storage of raw data  and transformed data (**optional**)
  2. Connector specific storage of the raw data. The responsibility for this data lies with the operator of the adapter (**optional**)
  3. The transformed data is stored within the Smart Data Framwork (**optional**)
5. Both the adapter and the transformer are developed by a third party (ISV, system integrator, etc.)

## Derived Tasks
- [ ] Slicing the illustration above into the different scenarios **@Architecture Workgroup**
- [ ] Development of different scenarios for the Open Integration Hub (Outside view on the system from a users perspective)
  - [ ] Collecting relevant use case scenarios as a task for the _Requirements & Integration Services_ workgroup **@All partners**
  - [ ] Development and central storage of a use case template **@Selim @Philipp @Daniel**
  - [ ] Development of an appropiate way to contribute the use cases **@Daniel @Philipp**

## Discussion
### Adapter
- Import and export of data
- The adapter knows where to request the data
- Lies within the Open Integration Hub
- Receives data from the Application and stores it in the raw data storage
- _Igor_: Different adapters request different data e.g. one adapter requests products and another one the relating prices
- _Selim_: From the point of view of Basaas, the adapter has to handle the incoming data and the sequence of the requests (e.g. for an _update user_ task) because it is part of the business logic. Data has to be stored in-memory until the task is fulfilled.  
- _Selim_: it is possible that - if an incompatibility between the mandatory fields of two ISV applications exist - the data is never inserted in the second application.
-  _Susanne_: It is possible to work with snapshots. Every ISV can receive a snapshot and the operations which need to be performed, to secure that all data is complete and up-to-date.
- It is possible that not every adapter is capable of performing triggers and actions. Some of them will only be able to perform triggers or actions
- **Question**: What happens if the data model of one application changes?
  - _Igor_: If the interface changes the whole integration is broken. A proper way to solve this way is the approach by Salesforce: They use versioning (previous versions of the interface still work) and propagate changes in the interface with a lead time of around 6 month. Thus every connected application has the chance to adjust to the changes.
  - The common interface of the Open Integration Hub will change much more often than the interfaces of the ISV applications
- **Question**: How to secure that an update in an ISV application which is triggered by an adapter is not send again to the Open Integration Hub?
  - _Susanne / Stephan_: It has to be possible to use versioning if the interface of the ISV application does not provide versioning
  - _Selim_: From the point of view of Basaas, the problem solving should lie wihtin the adapter
  - _Igor_: From the point of view of Elastic.io the problem solving should lie wihtin the Smart Data Framework
- **Question**: ISV decided, that data should only be inserted if all required data is available (E.g. Jeans in 5 different colors with pricing etc.). Where should the data be stored in the meantime?
  - _Selim_: Temporary storage of the data till the delivery. Afterwards the data is deleted.
  - _Igor_: Question: What if the data model changes in the meantime (when the data is stored)?
    - _Susanne & Stephan_: Dynamic lifetime is updated. There is no need to stop the whole production system.
- **Question**: How does the Open Integration Hub inform the adapter that it should request data?
  - _Igor_: Adapter has to be developed with the SDKs of the Open Integration Hub, thus it runs within the Open Integration Hub. (E.g. The adapter has to work with JSON and provide JSON-Schema.)
  - _Selim_: The adapter needs in some way to be triggered from the outside. The way how the adapters are triggered needs to be standardized.      



### Transformer
- A transformer is built on top of an adapter and
- Selim: The transformer knows the data model and master data schema. It has to include the logic how to transform the specifc data model into the master data schema and vice versa (Initial mapping is done by the transformer creator)
- Selim: A transformer should be able to collect and aggregate multiple requests and afterwards send it to the Open Integration Hub
- Question: How does a transformer look like? Code? Set of rules (xpas)
- If the mapping is done by third party (i.e. not by the ISV itself),
- Igor: Transformation can only start if all data are received (e.g. products and relating prices)
- Igor: Currently the mapper on Elastic.io is a set of rules
- **Transformer Scenario:** Data is received from the adapter in a raw format. The transformer transforms this data into a generic or domain specific model. After that the data lie within the Smart Data Framework in a normalized format. I.e. The transformer transorms a prorpietary format into a standard format.
- Igor: Elastic.io would like to store the result of the adapter.
- **Question:** What happens to the raw data after it was transformed?
    - Igor: They are stored.
- Selim: The data storage needs to be completely **optional**. The client has to decide if his/her data is stored. The data should be stored as long as subscribers exist, which are not acknowledged. When all subscribers are acknowledged, the data is deleted.
